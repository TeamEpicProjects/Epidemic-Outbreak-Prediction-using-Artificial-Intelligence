{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d9b89772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "import os\n",
    "import mysql.connector as connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d58c4",
   "metadata": {},
   "source": [
    "## ETL functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "480f36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(stock_files):\n",
    "    '''Extract the data from folder and concatenating all csv file in pandas dataframe'''\n",
    "    data = pd.concat((pd.read_csv(file,encoding='cp1252')\n",
    "          for file in stock_files), ignore_index = True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def tranfrom_data(data): \n",
    "    '''Transform dataset - Drop columns, Replace NaN value'''\n",
    "    \n",
    "    if ((\"Unnamed: 10\" in data) == True) and ((\"Unnamed: 9\" in data) == True) and ((\"ï»¿report_date\" in data) == True):\n",
    "        data['report_date'].fillna(data['ï»¿report_date'], inplace=True)\n",
    "        data = data.drop(['Unnamed: 10','Unnamed: 9','ï»¿report_date'], axis = 1)\n",
    "\n",
    "    elif (\"Unnamed: 9\" in data) == True and (\"ï»¿report_date\" in data) == True:\n",
    "        data['report_date'].fillna(data['ï»¿report_date'], inplace=True)\n",
    "        data = data.drop(['Unnamed: 9','ï»¿report_date'], axis = 1)\n",
    "\n",
    "    elif (\"ï»¿report_date\" in data) == True:\n",
    "        data['report_date'].fillna(data['ï»¿report_date'], inplace=True)\n",
    "        data = data.drop(['ï»¿report_date'], axis = 1)\n",
    "\n",
    "    elif (\"Unnamed: 9\" in data) == True:\n",
    "        data = data.drop(['Unnamed: 9'], axis = 1)\n",
    "    \n",
    "    # drop unnecessary columns\n",
    "    data = data.drop(['data_field_code','time_period','time_period_type','unit'], axis = 1)\n",
    "    # replace empty value with 'NaN'\n",
    "    data = data.fillna('NAN')\n",
    "    # rename col\n",
    "    data = data.rename(columns = {'value':'cases'})\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_data(data,country_name):\n",
    "    '''Load dataset into mysql database'''\n",
    "    # connect to the database\n",
    "    db = connect.connect(host=\"localhost\",user=\"root\",password=\"root\",database=\"zikadataset\")\n",
    "\n",
    "    mycursor = db.cursor()\n",
    "    mycursor.execute('use zikadataset')\n",
    "\n",
    "    # create table of different country\n",
    "    mycursor.execute(f\"\"\"create table {country_name}(report_date TEXT,\n",
    "                     location TEXT,\n",
    "                     location_type TEXT,\n",
    "                     data_field TEXT,\n",
    "                     cases TEXT)\"\"\")\n",
    "\n",
    "\n",
    "    # creating column list for insertion\n",
    "    cols = \"`,`\".join([str(i) for i in data.columns.tolist()])\n",
    "\n",
    "    # Insert DataFrame recrds one by one.\n",
    "    for i,row in data.iterrows():\n",
    "        sql = f\"INSERT INTO `{country_name}` (`\" +cols + \"`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "        mycursor.execute(sql, tuple(row))\n",
    "\n",
    "        # the connection is not autocommitted by default, so we must commit to save our changes\n",
    "        db.commit()\n",
    "    \n",
    "    return f'{country_name} Data loaded successfully'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bd9e521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina\n",
      "Argentina data loaded\n",
      "Haiti\n",
      "Haiti data loaded\n",
      "Nicaragua\n",
      "Nicaragua data loaded\n",
      "Puerto_Rico\n",
      "Puerto_Rico data loaded\n",
      "successful\n"
     ]
    }
   ],
   "source": [
    "def get_data():\n",
    "    dirList = os.listdir('data')\n",
    "    for i in dirList:\n",
    "        print(i)\n",
    "        stock_files = sorted(glob(f'data/{i}/*.csv'))\n",
    "        df = extract_data(stock_files)\n",
    "        df = tranfrom_data(df)\n",
    "        load_data(df,i)\n",
    "        print(f'{i} data loaded')\n",
    "        \n",
    "    return 'getting data...'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a10fa",
   "metadata": {},
   "source": [
    "## Count number of rows and cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbe544a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argentina', 'Brazil', 'Colombia', 'Dominican_Republic', 'Ecuador', 'El_Salvador', 'Guatemala', 'Haiti', 'Mexico', 'Nicaragua', 'Panama', 'Puerto_Rico', 'United_States', 'US_Virgin_Islands']\n",
      "\n",
      "{'Argentina': [5788, 9], 'Brazil': [9559, 9], 'Colombia': [158460, 9], 'Dominican_Republic': [28496, 9], 'Ecuador': [2943, 11], 'El_Salvador': [4160, 12], 'Guatemala': [4253, 10], 'Haiti': [52, 9], 'Mexico': [12960, 9], 'Nicaragua': [207, 9], 'Panama': [6445, 11], 'Puerto_Rico': [1118, 10], 'United_States': [5869, 9], 'US_Virgin_Islands': [2140, 10]}\n"
     ]
    }
   ],
   "source": [
    "def extract_data(stock_files):\n",
    "    '''Extract the data from folder and concatenating all csv file in pandas dataframe'''\n",
    "    data = pd.concat((pd.read_csv(file,encoding='cp1252')\n",
    "          for file in stock_files), ignore_index = True)\n",
    "    return data\n",
    "\n",
    "country = {}\n",
    "\n",
    "# find all dataset folders\n",
    "dirList = os.listdir('Dataset')\n",
    "print(dirList)\n",
    "\n",
    "for i in dirList:\n",
    "    # Iterate each folder and merge all csv file of that folder\n",
    "    stock_files = sorted(glob(f'Dataset/{i}/*.csv'))\n",
    "    \n",
    "    # pass all csv to extract_data function\n",
    "    df = extract_data(stock_files)\n",
    "    \n",
    "    # Count total number of rows and cols\n",
    "    rows_and_cols = {i:[df.shape[0],df.shape[1]]}\n",
    "    country.update(rows_and_cols)\n",
    "    \n",
    "print()\n",
    "print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a94a9019",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>5788</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>9559</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colombia</th>\n",
       "      <td>158460</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominican_Republic</th>\n",
       "      <td>28496</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ecuador</th>\n",
       "      <td>2943</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>El_Salvador</th>\n",
       "      <td>4160</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guatemala</th>\n",
       "      <td>4253</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haiti</th>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>12960</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicaragua</th>\n",
       "      <td>207</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Panama</th>\n",
       "      <td>6445</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puerto_Rico</th>\n",
       "      <td>1118</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United_States</th>\n",
       "      <td>5869</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_Virgin_Islands</th>\n",
       "      <td>2140</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Rows  Columns\n",
       "Argentina             5788        9\n",
       "Brazil                9559        9\n",
       "Colombia            158460        9\n",
       "Dominican_Republic   28496        9\n",
       "Ecuador               2943       11\n",
       "El_Salvador           4160       12\n",
       "Guatemala             4253       10\n",
       "Haiti                   52        9\n",
       "Mexico               12960        9\n",
       "Nicaragua              207        9\n",
       "Panama                6445       11\n",
       "Puerto_Rico           1118       10\n",
       "United_States         5869        9\n",
       "US_Virgin_Islands     2140       10"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame.from_dict(country, orient ='index', columns=['Rows','Columns'])\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def609a",
   "metadata": {},
   "source": [
    "## Checking all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "48c4a353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argentina', 'Brazil', 'Colombia', 'Dominican_Republic', 'Ecuador', 'El_Salvador', 'Guatemala', 'Haiti', 'Mexico', 'Nicaragua', 'Panama', 'Puerto_Rico', 'United_States', 'US_Virgin_Islands']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>location</th>\n",
       "      <th>location_type</th>\n",
       "      <th>data_field</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-13</td>\n",
       "      <td>Brazil-Acre</td>\n",
       "      <td>state</td>\n",
       "      <td>microcephaly_under_investigation</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-13</td>\n",
       "      <td>Brazil-Alagoas</td>\n",
       "      <td>state</td>\n",
       "      <td>microcephaly_under_investigation</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-13</td>\n",
       "      <td>Brazil-Amapa</td>\n",
       "      <td>state</td>\n",
       "      <td>microcephaly_under_investigation</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-13</td>\n",
       "      <td>Brazil-Amazonas</td>\n",
       "      <td>state</td>\n",
       "      <td>microcephaly_under_investigation</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-13</td>\n",
       "      <td>Brazil-Bahia</td>\n",
       "      <td>state</td>\n",
       "      <td>microcephaly_under_investigation</td>\n",
       "      <td>583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9554</th>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>Brazil-Mato_Grosso_do_Sul</td>\n",
       "      <td>state</td>\n",
       "      <td>zika_reported</td>\n",
       "      <td>762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>Brazil-Mato_Grosso</td>\n",
       "      <td>state</td>\n",
       "      <td>zika_reported</td>\n",
       "      <td>19985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9556</th>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>Brazil-Goias</td>\n",
       "      <td>state</td>\n",
       "      <td>zika_reported</td>\n",
       "      <td>4132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9557</th>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>Brazil-Distrito_Federal</td>\n",
       "      <td>state</td>\n",
       "      <td>zika_reported</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>country</td>\n",
       "      <td>zika_reported</td>\n",
       "      <td>165932.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9559 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     report_date                   location location_type  \\\n",
       "0     2016-02-13                Brazil-Acre         state   \n",
       "1     2016-02-13             Brazil-Alagoas         state   \n",
       "2     2016-02-13               Brazil-Amapa         state   \n",
       "3     2016-02-13            Brazil-Amazonas         state   \n",
       "4     2016-02-13               Brazil-Bahia         state   \n",
       "...          ...                        ...           ...   \n",
       "9554  2016-06-11  Brazil-Mato_Grosso_do_Sul         state   \n",
       "9555  2016-06-11         Brazil-Mato_Grosso         state   \n",
       "9556  2016-06-11               Brazil-Goias         state   \n",
       "9557  2016-06-11    Brazil-Distrito_Federal         state   \n",
       "9558  2016-06-11                     Brazil       country   \n",
       "\n",
       "                            data_field     cases  \n",
       "0     microcephaly_under_investigation      22.0  \n",
       "1     microcephaly_under_investigation      90.0  \n",
       "2     microcephaly_under_investigation       NAN  \n",
       "3     microcephaly_under_investigation       NAN  \n",
       "4     microcephaly_under_investigation     583.0  \n",
       "...                                ...       ...  \n",
       "9554                     zika_reported     762.0  \n",
       "9555                     zika_reported   19985.0  \n",
       "9556                     zika_reported    4132.0  \n",
       "9557                     zika_reported     367.0  \n",
       "9558                     zika_reported  165932.0  \n",
       "\n",
       "[9559 rows x 5 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_data(stock_files):\n",
    "    '''Extract the data from folder and concatenating all csv file in pandas dataframe'''\n",
    "    data = pd.concat((pd.read_csv(file,encoding='cp1252')\n",
    "          for file in stock_files), ignore_index = True)\n",
    "    return data\n",
    "\n",
    "def tranfrom_data(data):  \n",
    "    if ((\"Unnamed: 10\" in data) == True) and ((\"Unnamed: 9\" in data) == True) and ((\"ï»¿report_date\" in data) == True):\n",
    "        data['report_date'].fillna(data['ï»¿report_date'], inplace=True)\n",
    "        data = data.drop(['Unnamed: 10','Unnamed: 9','ï»¿report_date'], axis = 1)\n",
    "\n",
    "    elif (\"Unnamed: 9\" in data) == True and (\"ï»¿report_date\" in data) == True:\n",
    "        data['report_date'].fillna(data['ï»¿report_date'], inplace=True)\n",
    "        data = data.drop(['Unnamed: 9','ï»¿report_date'], axis = 1)\n",
    "\n",
    "    elif (\"ï»¿report_date\" in data) == True:\n",
    "        data['report_date'].fillna(data['ï»¿report_date'], inplace=True)\n",
    "        data = data.drop(['ï»¿report_date'], axis = 1)\n",
    "\n",
    "    elif (\"Unnamed: 9\" in data) == True:\n",
    "        data = data.drop(['Unnamed: 9'], axis = 1)\n",
    "        \n",
    "    data = data.drop(['data_field_code','time_period','time_period_type','unit'], axis = 1)\n",
    "    data = data.fillna('NAN')\n",
    "    data = data.rename(columns = {'value':'cases'})\n",
    "    \n",
    "    return data\n",
    "\n",
    "# find all dataset folders\n",
    "dirList = os.listdir('Dataset')\n",
    "print(dirList)\n",
    "\n",
    "# Iterate each folder and merge all csv file of that folder\n",
    "stock_files = sorted(glob(f'Dataset/{dirList[1]}/*.csv'))\n",
    " \n",
    "# pass all csv to extract_data function\n",
    "data = extract_data(stock_files)\n",
    "data = tranfrom_data(data)\n",
    "        \n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
